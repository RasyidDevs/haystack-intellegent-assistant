{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ded6c7c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Enviroments\\anaconda3\\envs\\day45-haystack\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from haystack import Pipeline, component\n",
    "from haystack.components.embedders import SentenceTransformersTextEmbedder\n",
    "from haystack.components.agents import Agent\n",
    "from haystack.components.generators.chat import OpenAIChatGenerator\n",
    "from haystack_integrations.document_stores.mongodb_atlas import MongoDBAtlasDocumentStore\n",
    "from haystack.utils import Secret\n",
    "from haystack.components.builders import ChatPromptBuilder, PromptBuilder\n",
    "from haystack.dataclasses import ChatMessage\n",
    "from haystack.tools.tool import Tool\n",
    "from haystack_experimental.chat_message_stores.in_memory import InMemoryChatMessageStore\n",
    "from haystack_experimental.components.retrievers import ChatMessageRetriever\n",
    "from haystack_experimental.components.writers import ChatMessageWriter\n",
    "from haystack_integrations.components.retrievers.mongodb_atlas import MongoDBAtlasEmbeddingRetriever\n",
    "from haystack.components.generators import OpenAIGenerator\n",
    "from pymongo import MongoClient\n",
    "from typing import List,Annotated\n",
    "from haystack.components.routers import ConditionalRouter\n",
    "from haystack.dataclasses import Document\n",
    "from getpass import getpass\n",
    "import re\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a86c53",
   "metadata": {},
   "source": [
    "### LOGGER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e20b04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import logging\n",
    "# from haystack import tracing\n",
    "# from haystack.tracing.logging_tracer import LoggingTracer\n",
    "\n",
    "# logging.basicConfig(format=\"%(levelname)s - %(name)s -  %(message)s\", level=logging.WARNING)\n",
    "# logging.getLogger(\"haystack\").setLevel(logging.DEBUG)\n",
    "\n",
    "# tracing.tracer.is_content_tracing_enabled = True # to enable tracing/logging content (inputs/outputs)\n",
    "# tracing.enable_tracing(LoggingTracer(tags_color_strings={\"haystack.component.input\": \"\\x1b[1;31m\", \"haystack.component.name\": \"\\x1b[1;34m\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72354592",
   "metadata": {},
   "source": [
    "### ENV VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abac1ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mongo_connection_string = Secret.from_token(os.getenv(\"MONGO_CONNECTION_STRING\"))\n",
    "openai_api_key = Secret.from_token(os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecabc3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_message_store = InMemoryChatMessageStore()\n",
    "document_store_product = MongoDBAtlasDocumentStore(\n",
    "    database_name=\"depato_store\",\n",
    "    collection_name=\"products\",\n",
    "    vector_search_index=\"vector_index\",\n",
    "    full_text_search_index=\"search_index\",\n",
    "    mongo_connection_string=mongo_connection_string\n",
    ")\n",
    "document_store_common = MongoDBAtlasDocumentStore(\n",
    "    database_name=\"depato_store\",\n",
    "    collection_name=\"common_information\",\n",
    "    vector_search_index=\"vector_index_common\",\n",
    "    full_text_search_index=None,\n",
    "    mongo_connection_string=mongo_connection_string\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b71444",
   "metadata": {},
   "source": [
    "## Membuat Paraphraser Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f89d791d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParaphraserPipeline:\n",
    "    def __init__(self,chat_message_store):\n",
    "        self.memory_retriever = ChatMessageRetriever(chat_message_store)\n",
    "        self.pipeline = Pipeline()\n",
    "        self.pipeline.add_component(\"prompt_builder\",ChatPromptBuilder(variables=[\"query\",\"memories\"],required_variables=[\"query\", \"memories\"],))\n",
    "        self.pipeline.add_component(\"generator\", OpenAIChatGenerator(model=\"gpt-4.1-2025-04-14\", api_key=Secret.from_token(os.environ[\"OPENAI_API_KEY\"])))\n",
    "        self.pipeline.add_component(\"memory_retriever\", self.memory_retriever)\n",
    "\n",
    "        self.pipeline.connect(\"prompt_builder.prompt\", \"generator.messages\")\n",
    "        self.pipeline.connect(\"memory_retriever\", \"prompt_builder.memories\")\n",
    "    \n",
    "    def run(self, query):\n",
    "        messages = [\n",
    "            ChatMessage.from_system(\n",
    "                \"You are a helpful assistant that paraphrases user queries based on previous conversations.\"\n",
    "            ),\n",
    "            ChatMessage.from_user(\n",
    "                \"\"\"\n",
    "                Please paraphrase the following query based on the conversation history provided below. If the conversation history is empty, please return the query as is.\n",
    "                history:\n",
    "                {% for memory in memories %}\n",
    "                    {{memory.text}}\n",
    "                {% endfor %}\n",
    "                query: {{query}}\n",
    "                answer:\n",
    "                \"\"\"\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        res = self.pipeline.run(\n",
    "            data = {\n",
    "                \"prompt_builder\":{\n",
    "                    \"query\": query,\n",
    "                    \"template\": messages\n",
    "                },\n",
    "            \n",
    "            },\n",
    "            include_outputs_from=[\"generator\"]\n",
    "        )\n",
    "        print(\"Pipeline Input\", query)\n",
    "        return res[\"generator\"][\"replies\"][0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bff867b",
   "metadata": {},
   "source": [
    "## Membuat History Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce2d47ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatHistoryPipeline:\n",
    "    def __init__(self, chat_message_store):\n",
    "        self.chat_message_store = chat_message_store\n",
    "        self.pipeline = Pipeline()\n",
    "        self.pipeline.add_component(\"memory_retriever\", ChatMessageRetriever(chat_message_store))\n",
    "        self.pipeline.add_component(\"prompt_builder\", PromptBuilder(variables=[\"memories\"], required_variables=[\"memories\"], template=\"\"\"\n",
    "        Previous Conversations history:\n",
    "        {% for memory in memories %}\n",
    "            {{memory.text}}\n",
    "        {% endfor %}\n",
    "        \"\"\")\n",
    "        )\n",
    "        self.pipeline.connect(\"memory_retriever\", \"prompt_builder.memories\")\n",
    "\n",
    "    def run(self):\n",
    "        res = self.pipeline.run(\n",
    "            data = {},\n",
    "            include_outputs_from=[\"prompt_builder\"]\n",
    "        )\n",
    "\n",
    "        return res[\"prompt_builder\"][\"prompt\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1724f1ec",
   "metadata": {},
   "source": [
    "## Membuat Route Common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c66e731",
   "metadata": {},
   "outputs": [],
   "source": [
    "class  CommonRoute:\n",
    "    def __init__(self, document_store):\n",
    "        self.document_store = document_store\n",
    "        template_common_message = [\n",
    "            ChatMessage.from_system(\n",
    "            \"\"\"\n",
    "            You are smart personal assistant system to help customer find common information\n",
    "            Answer the user's question using only the provided context.\n",
    "            Maintain the same language as the question.   \n",
    "            Context:\n",
    "            {{ context | map(attribute='content') | join(\" \") | replace(\"\\n\", \" \")}}   \n",
    "            Instructions:\n",
    "            1. Only use information from the context to answer.\n",
    "            2. If the context does not contain the required Context, respond with:\n",
    "            \"I'm sorry, I can't answer that right now.\"\n",
    "            3. Keep the answer concise and clear.          \n",
    "            \"\"\"\n",
    "        ),\n",
    "            ChatMessage.from_user(\n",
    "                \"{{ query }}\"\n",
    "            )\n",
    "        ]\n",
    "        self.pipeline = Pipeline()\n",
    "        self.pipeline.add_component(\"embedder_common\", SentenceTransformersTextEmbedder())\n",
    "        self.pipeline.add_component(\"retriever_common\", MongoDBAtlasEmbeddingRetriever( document_store=document_store, top_k=6))\n",
    "        self.pipeline.add_component(\"prompt_builder_common\", ChatPromptBuilder(template=template_common_message))\n",
    "        self.pipeline.add_component(\"generator_common\", OpenAIChatGenerator(api_key=openai_api_key, model=\"gpt-4.1\"))\n",
    "\n",
    "        self.pipeline.connect(\"embedder_common.embedding\", \"retriever_common.query_embedding\")\n",
    "        self.pipeline.connect(\"retriever_common.documents\", \"prompt_builder_common.context\")\n",
    "        self.pipeline.connect(\"prompt_builder_common.prompt\", \"generator_common.messages\")\n",
    "    def run(self, query):\n",
    "        res = self.pipeline.run(\n",
    "            data={\n",
    "                \"embedder_common\":{\"text\" : query},\n",
    "                \"prompt_builder_common\" : {\"query\" : query},\n",
    "            }, include_outputs_from=[\"generator_common\"]\n",
    "        )\n",
    "        return res[\"generator_common\"][\"replies\"][0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a894981",
   "metadata": {},
   "source": [
    "## Membuat Metadata Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03f2833c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MongoDBAtlas:\n",
    "    def __init__(self, mongo_connection_string:str):\n",
    "        self.client = MongoClient(mongo_connection_string)\n",
    "        self.db = self.client.depato_store\n",
    "        self.material_collection = self.db.materials\n",
    "        self.category_collection = self.db.categories\n",
    "\n",
    "    def get_materials(self):\n",
    "        return [doc['name'] for doc in self.material_collection.find()]\n",
    "\n",
    "    def get_categories(self):\n",
    "        return [doc['name'] for doc in self.category_collection.find()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60a041b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component\n",
    "class GetMaterials:\n",
    "    def __init__(self):\n",
    "        self.db = MongoDBAtlas(os.getenv(\"MONGO_CONNECTION_STRING\"))\n",
    "    @component.output_types(materials=List[str])\n",
    "    def run(self):\n",
    "        materials = self.db.get_materials()\n",
    "        return {\"materials\": materials}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a079bda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component\n",
    "class GetCategories:\n",
    "    def __init__(self):\n",
    "        self.db = MongoDBAtlas(os.environ['MONGO_CONNECTION_STRING'])\n",
    "    \n",
    "    @component.output_types(categories=List[str])\n",
    "    def run(self):\n",
    "        categories = self.db.get_categories()\n",
    "        return {\"categories\": categories}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce9b846c",
   "metadata": {},
   "outputs": [],
   "source": [
    "METADATA_FILTER_TEMPLATE = \"\"\"\n",
    "You are a json generator that have a job to generate json based on the input.\n",
    "The return json should be in the format:\n",
    "```json\n",
    "{\n",
    "    \"operator\": \"AND\",\n",
    "    \"conditions\":[\n",
    "        {\"field\": \"meta.category\", \"operator\":\"==\", \"value\": <category>},\n",
    "        {\"field\": \"meta.material\", \"operator\":\"==\", \"value\": <material>},\n",
    "        {\"field\": \"meta.gender\", \"operator\":\"==\", \"value\" : <male|female|unisex>},\n",
    "        {\"field\": \"meta.price\", \"operator\":<\"<=\"|\">=\"|\"==\">, \"value\": <price>}\n",
    "    ]\n",
    "}\n",
    "```\n",
    "The json key above can be omiitted if the value is not provided in the input, so please make sure to only return the keys that are provided in the input.\n",
    "\n",
    "For the material and category, you can only use the material and category that are provided below:\n",
    "Materials: [ {% for material in materials %} {{ material }} {% if not loop.last %}, {% endif %} {% endfor %} ]\n",
    "\n",
    "Categories: [ {% for category in categories %} {{ category }} {% if not loop.last %}, {% endif %} {% endfor %} ]\n",
    "\n",
    "if the input does not contain any of the keys above, you should return an empty json object like this:\n",
    "```json\n",
    "{}\n",
    "```\n",
    "Sometimes the material and category can be negated, so you should also handle that by using the operator \"!=\" for material and category. \n",
    "\n",
    "Sometimes the material and category is not explicitly mentioned, you should analyze which material and category is the most suitable based on the input, and return the json with the material and category that you think is the most suitable.\n",
    "\n",
    "Nestede conditions are allowed, for nested conditions, you can use \"OR\" and \"AND\" as the operator, and the conditions should be in the \"conditions\" array.\n",
    "\n",
    "if user said the price around some value, please find the price between those value -10 and value +10.\n",
    "\n",
    "The example of the result are expected to be like this:\n",
    "\n",
    "1. Input: \"can you give me a adress with cotton material?\"\n",
    "output:\n",
    "```json\n",
    "{\n",
    "    \"operator\": \"AND\",\n",
    "    \"conditions\": [\n",
    "        {\"field\": \"meta.material\", \"operator\": \"==\", \"value\": \"Cotton\"},\n",
    "        {\"field\": \"meta.category\", \"operator\": \"==\", \"value\": \"Dresses/Jumpsuits\"}\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "2. Input: \"Give me Shirt that is not made of cotton and has a price less than $100\"\n",
    "output:\n",
    "```json\n",
    "{\n",
    "    \"operator\": \"AND\",\n",
    "    \"conditions\": [\n",
    "        {\"field\": \"meta.category\", \"operator\": \"==\", \"value\": \"Tops\"},\n",
    "        {\"field\": \"meta.material\", \"operator\": \"!=\", \"value\": \"Cotton\"},\n",
    "        {\"field\": \"meta.price\", \"operator\": \"<=\", \"value\": 100}\n",
    "    ]\n",
    "}\n",
    "3. Input: \"I want a dress that is not hot and has a price greater than $50\"\n",
    "output:\n",
    "```json\n",
    "{\n",
    "    \"operator\": \"AND\",\n",
    "    \"conditions\": [\n",
    "        {\"field\": \"meta.category\", \"operator\": \"==\", \"value\": \"Dresses/Jumpsuits\"},\n",
    "        {\"field\": \"meta.price\", \"operator\": \">=\", \"value\": 50},\n",
    "        {\n",
    "            \"operator\": \"OR\",\n",
    "            \"conditions\": [\n",
    "                {\"field\": \"meta.material\", \"operator\": \"==\", \"value\": \"Cotton\"},\n",
    "                {\"field\": \"meta.material\", \"operator\": \"==\", \"value\": \"Polyester\"}\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "4. Input i want tops that have price between $20 and $50\n",
    "output:\n",
    "```json\n",
    "{\n",
    "    \"operator\": \"AND\",\n",
    "    \"conditions\": [\n",
    "        {\"field\": \"meta.category\", \"operator\": \"==\", \"value\": \"Tops\"},\n",
    "        {\n",
    "            \"operator\": \"AND\",\n",
    "            \"conditions\":[\n",
    "                {\"field\": \"meta.price\", \"operator\": \">=\", \"value\": 20},\n",
    "                {\"field\": \"meta.price\", \"operator\": \"<=\", \"value\": 50}\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```\n",
    "5. Input: I want the dress price around $50\n",
    "output: \n",
    "```json\n",
    "{\n",
    "    \"operator\": \"AND\",\n",
    "    \"conditions\": [\n",
    "        {\"field\": \"meta.category\", \"operator\": \"==\", \"value\": \"Dresses/Jumpsuits\"},\n",
    "        {\n",
    "            \"operator\": \"AND\",\n",
    "            \"conditions\":[\n",
    "                {\"field\": \"meta.price\", \"operator\": \">=\", \"value\": 40},\n",
    "                {\"field\": \"meta.price\", \"operator\": \"<=\", \"value\": 60}\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```\n",
    "6. Input: {{input}}\n",
    "output:\n",
    "\n",
    "```\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41ed92ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetaDataFilterPipeline:\n",
    "    def __init__(self, get_materials, get_categories, template):\n",
    "        self.get_materials = get_materials\n",
    "        self.get_categories = get_categories\n",
    "        self.template = template\n",
    "\n",
    "        self.pipeline = Pipeline()\n",
    "        self.pipeline.add_component(\"materials\", GetMaterials())\n",
    "        self.pipeline.add_component(\"categories\", GetCategories())\n",
    "        self.pipeline.add_component(\n",
    "            \"prompt_builder\",\n",
    "            PromptBuilder(\n",
    "                template=self.template,\n",
    "                required_variables=[\"input\", \"materials\", \"categories\"],\n",
    "            )\n",
    "        )\n",
    "        self.pipeline.add_component(\"generator\", OpenAIGenerator(\n",
    "            model=\"gpt-4.1-2025-04-14\",\n",
    "            api_key=Secret.from_token(os.environ['OPENAI_API_KEY'])\n",
    "        ))\n",
    "        self.pipeline.connect(\"materials.materials\", \"prompt_builder.materials\")\n",
    "        self.pipeline.connect(\"categories.categories\", \"prompt_builder.categories\")\n",
    "        self.pipeline.connect(\"prompt_builder\",\"generator\")\n",
    "\n",
    "    def run(self, query: str):\n",
    "        res = self.pipeline.run(\n",
    "            data={\n",
    "                \"prompt_builder\": {\n",
    "                    \"input\": query,\n",
    "                },\n",
    "            },\n",
    "        )\n",
    "        return res[\"generator\"][\"replies\"][0]\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0404839",
   "metadata": {},
   "source": [
    "## Membuat Products Route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e2417ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductsRoute:\n",
    "    def __init__(self, chat_message_store, document_store):\n",
    "        self.chat_message_store = chat_message_store\n",
    "        self.document_store = document_store\n",
    "        self.pipeline = Pipeline()\n",
    "        self.pipeline.add_component(\"embedder_products\" , SentenceTransformersTextEmbedder())\n",
    "        self.pipeline.add_component(\"retriever_products\", MongoDBAtlasEmbeddingRetriever(document_store=document_store,top_k=10))\n",
    "        self.pipeline.add_component(\"prompt_builder_products\", ChatPromptBuilder(variables=[\"query\",\"documents\"],required_variables=[\"query\", \"documents\"]))\n",
    "        self.pipeline.add_component(\"generator_products\", OpenAIChatGenerator(model=\"gpt-4.1-2025-04-14\", api_key=Secret.from_token(os.environ[\"OPENAI_API_KEY\"])))        \n",
    "    \n",
    "        self.pipeline.connect(\"embedder_products.embedding\" , \"retriever_products.query_embedding\")\n",
    "        self.pipeline.connect(\"retriever_products.documents\", \"prompt_builder_products.documents\")\n",
    "        self.pipeline.connect(\"prompt_builder_products.prompt\", \"generator_products.messages\")\n",
    "\n",
    "    def run(self, query: str,  filter: dict = {}):\n",
    "        messages = [\n",
    "            ChatMessage.from_system(\n",
    "                  \"\"\"\n",
    "                    You are a shop assiistant that helps users find the best products in a shopping mall.\n",
    "                    You will be give a query and list of products. Your task is to generate a list of products that best match the query.\n",
    "                    USE THE SAME LANGUAGE AS THE QUERY!\n",
    "                    The output should be a list of products in the following format:\n",
    "                    .  \n",
    "                    1. Title: \n",
    "                    Price: \n",
    "                    Material: \n",
    "                    Category: \n",
    "                    Brand: \n",
    "                    Recommendation: \n",
    "\n",
    "                    From the format above, you should pay attention to the following:\n",
    "                    1.  should be a short summary of the query.\n",
    "                    2.  should be a number starting from 1.\n",
    "                    3.  should be the name of the product, this product name can be found from the product_name field.\n",
    "                    4.  should be the price of the product, this product price can be found from the product_price field.\n",
    "                    5.  should be the material of the product, this product material can be found from the product_material field.\n",
    "                    6.  should be the category of the product, this product category can be found from the product_category field.\n",
    "                    7.  should be the brand of the product, this product brand can be found from the product_brand field.\n",
    "                    8.  should be the recommendation of the product, you should give a recommendation why this product is recommended, please pay attentation to the product_content field. \n",
    "\n",
    "\n",
    "                    You should only return the list of products that best match the query, do not return any other information.\n",
    "                    the products are:\n",
    "                    {% for product in documents %}\n",
    "                    ===========================================================\n",
    "                    {{loop.index + 1}}. product_name: {{ product.meta.title }}\n",
    "                    product_price: {{ product.meta.price }}\n",
    "                    product_material: {{ product.meta.material }}\n",
    "                    product_category: {{ product.meta.category }}\n",
    "                    product_brand: {{ product.meta.brand }}\n",
    "                    product_content: {{ product.content}}\n",
    "                    {% endfor %}\n",
    "\n",
    "                    ===========================================================\n",
    "\n",
    "                    Answer:\n",
    "\n",
    "                    \"\"\"\n",
    "            ),\n",
    "            ChatMessage.from_user(\n",
    "                \"\"\"\n",
    "                 The query is: {{query}}\n",
    "                \"\"\"\n",
    "            )\n",
    "        ]\n",
    "        res = self.pipeline.run(\n",
    "            data={\n",
    "                 \"embedder_products\":{\n",
    "                    \"text\": query,\n",
    "                },\n",
    "                \"retriever_products\":{\n",
    "                    \"filters\":filter\n",
    "                },\n",
    "               \"prompt_builder_products\":{\n",
    "                   \"query\": query,\n",
    "                   \"template\": messages\n",
    "               },\n",
    "\n",
    "            },\n",
    "            include_outputs_from=[\"generator_prodcts\", \"prompt_builder_products\"]\n",
    "        )\n",
    "        print(res[\"prompt_builder_products\"][\"prompt\"])\n",
    "        return res[\"generator_products\"][\"replies\"][0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "557d61ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "paraprahser_pipeline = ParaphraserPipeline(chat_message_store=chat_message_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2317504d",
   "metadata": {},
   "source": [
    "## Tools for CommonRoute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ccd5f652",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ChatPromptBuilder has 2 prompt variables, but `required_variables` is not set. By default, all prompt variables are treated as optional, which may lead to unintended behavior in multi-branch pipelines. To avoid unexpected execution, ensure that variables intended to be required are explicitly set in `required_variables`.\n"
     ]
    }
   ],
   "source": [
    "common_route = CommonRoute(document_store=document_store_common)\n",
    "products_route = ProductsRoute(chat_message_store=chat_message_store, document_store=document_store_product)\n",
    "def retrieve_and_generate_common(query:str):\n",
    "    pharaprased_query = paraprahser_pipeline.run(query)\n",
    "    return common_route.run(query=pharaprased_query)\n",
    "common_tool = Tool(\n",
    "    name=\"retrieve_and_generate_common_information\",\n",
    "    description=\"use this to retrieve common information based on the query\",\n",
    "    function=retrieve_and_generate_common,\n",
    "    parameters= {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"query\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The user query to retrieve common_information and generate an answer.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"query\"]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0962a917",
   "metadata": {},
   "source": [
    "## Tools for Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3a07e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieve_and_generate_pipeline = ProductsRoute(chat_message_store=chat_message_store, document_store=document_store_product)\n",
    "metadata_filter_pipeline = MetaDataFilterPipeline(\n",
    "    get_materials=GetMaterials(),\n",
    "    get_categories=GetCategories(),\n",
    "    template=METADATA_FILTER_TEMPLATE\n",
    ")\n",
    "\n",
    "def retrieve_and_generate_products(query: Annotated[str, \"User query\"]):\n",
    "    \"\"\"\n",
    "    This tool retrieves products based on user query and generates an answer.\n",
    "    \"\"\"\n",
    "    pharaprased_query = paraprahser_pipeline.run(query)\n",
    "    result = metadata_filter_pipeline.run(pharaprased_query)\n",
    "    data = {}\n",
    "    try:\n",
    "        json_match = re.search(r'```json\\n(.*?)\\n```', result, re.DOTALL)\n",
    "        if json_match:\n",
    "           json_str = json_match.group(1)\n",
    "           data = json.loads(json_str)\n",
    "        else:\n",
    "            data = {}\n",
    "    except Exception as e:\n",
    "          data = {}\n",
    "    return retrieve_and_generate_pipeline.run(pharaprased_query,data)\n",
    "\n",
    "product_tool = Tool(\n",
    "    name=\"retrieve_and_generate_recommendation\",\n",
    "    description=\"Use this tool to create metadata filter, retrieve products based on user query, and generate an answer.\",\n",
    "    function=retrieve_and_generate_products,\n",
    "    parameters= {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"query\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The user query to retrieve products and generate an answer.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"query\"]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd115d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(\n",
    "    chat_generator = OpenAIChatGenerator(model=\"gpt-4.1-2025-04-14\", api_key=Secret.from_token(os.environ[\"OPENAI_API_KEY\"])),\n",
    "    tools=[product_tool, common_tool],\n",
    "    system_prompt=\"\"\"\n",
    "   You are a helpful shop assistant AI agent. Your job is to provide:\n",
    "\n",
    "    1. Product recommendations (based on material, price, and category).\n",
    "    2. Common shop information (Shipping, Returns, Privacy Policy, Payment, Terms & Conditions, etc).\n",
    "\n",
    "    DECISION LOGIC:\n",
    "    - If the user asks about common/shop information → use the common information tool.\n",
    "    - If the user asks about products:\n",
    "        • Analyze the user query and conversation history.\n",
    "        • If enough information is provided (material/price/category), call the product tool.\n",
    "        • If information is insufficient, ask the user for clarification.\n",
    "\n",
    "    WORKFLOW RULES:\n",
    "    - Only call ONE tool at a time.\n",
    "    - After a tool returns results, evaluate:\n",
    "        “Am I done?”\n",
    "        • If yes → respond with the final answer.\n",
    "        • If no → call another tool.\n",
    "    - If the user's request is outside product or shop information, politely decline.\n",
    "\n",
    "    Your responses must stay focused on these two domains only.\n",
    "    \"\"\",\n",
    "    exit_conditions=[\"text\"],\n",
    "    max_agent_steps= 20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4fb1448",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history_pipeline = ChatHistoryPipeline(chat_message_store=chat_message_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b41b22a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline Input prosedur dan kebijakan jika barang hilang dalam pengiriman\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  9.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: Maaf, saat ini saya belum dapat memberikan informasi mengenai prosedur atau kebijakan jika barang hilang dalam pengiriman. Anda dapat menghubungi layanan pelanggan toko kami untuk bantuan lebih lanjut terkait kasus barang hilang. Apakah ada informasi lain yang bisa saya bantu?\n"
     ]
    }
   ],
   "source": [
    "agent.warm_up()\n",
    "chat_message_writer = ChatMessageWriter(chat_message_store)\n",
    "query = input(\"Masukkan query: \")\n",
    "\n",
    "history = chat_history_pipeline.run()\n",
    "messages = [ChatMessage.from_system(history),ChatMessage.from_user(query)]\n",
    "chat_message_writer.run([ChatMessage.from_user(query)])\n",
    "response = agent.run(messages=messages)\n",
    "response_text = response[\"messages\"][-1].text\n",
    "\n",
    "messages_save = [\n",
    "    ChatMessage.from_assistant(response_text)\n",
    "]\n",
    "chat_message_writer.run(messages_save)\n",
    "print(f\"Response: {response_text}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "day45-haystack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

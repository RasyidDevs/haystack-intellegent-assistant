{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ded6c7c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Enviroments\\anaconda3\\envs\\day45-haystack\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from haystack import Pipeline, component\n",
    "from haystack.components.embedders import SentenceTransformersTextEmbedder\n",
    "from haystack.components.agents import Agent\n",
    "from haystack.components.generators.chat import OpenAIChatGenerator\n",
    "from haystack_integrations.document_stores.mongodb_atlas import MongoDBAtlasDocumentStore\n",
    "from haystack.utils import Secret\n",
    "from haystack.components.builders import ChatPromptBuilder, PromptBuilder\n",
    "from haystack.dataclasses import ChatMessage\n",
    "from haystack.tools.tool import Tool\n",
    "from haystack_experimental.chat_message_stores.in_memory import InMemoryChatMessageStore\n",
    "from haystack_experimental.components.retrievers import ChatMessageRetriever\n",
    "from haystack_experimental.components.writers import ChatMessageWriter\n",
    "from haystack_integrations.components.retrievers.mongodb_atlas import MongoDBAtlasEmbeddingRetriever\n",
    "from haystack.components.generators import OpenAIGenerator\n",
    "from pymongo import MongoClient\n",
    "from typing import List,Annotated\n",
    "from haystack.components.routers import ConditionalRouter\n",
    "from haystack.dataclasses import Document\n",
    "from getpass import getpass\n",
    "import re\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a86c53",
   "metadata": {},
   "source": [
    "### LOGGER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e20b04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from haystack import tracing\n",
    "from haystack.tracing.logging_tracer import LoggingTracer\n",
    "\n",
    "logging.basicConfig(format=\"%(levelname)s - %(name)s -  %(message)s\", level=logging.WARNING)\n",
    "logging.getLogger(\"haystack\").setLevel(logging.DEBUG)\n",
    "\n",
    "tracing.tracer.is_content_tracing_enabled = True # to enable tracing/logging content (inputs/outputs)\n",
    "tracing.enable_tracing(LoggingTracer(tags_color_strings={\"haystack.component.input\": \"\\x1b[1;31m\", \"haystack.component.name\": \"\\x1b[1;34m\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72354592",
   "metadata": {},
   "source": [
    "### ENV VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abac1ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mongo_connection_string = Secret.from_token(os.getenv(\"MONGO_CONNECTION_STRING\"))\n",
    "openai_api_key = Secret.from_token(os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecabc3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_message_store = InMemoryChatMessageStore()\n",
    "document_store_product = MongoDBAtlasDocumentStore(\n",
    "    database_name=\"depato_store\",\n",
    "    collection_name=\"products\",\n",
    "    vector_search_index=\"vector_index\",\n",
    "    full_text_search_index=\"search_index\",\n",
    "    mongo_connection_string=mongo_connection_string\n",
    ")\n",
    "document_store_common = MongoDBAtlasDocumentStore(\n",
    "    database_name=\"depato_store\",\n",
    "    collection_name=\"common_informataion\",\n",
    "    vector_search_index=\"vector_index_ccommon\",\n",
    "    full_text_search_index=None,\n",
    "    mongo_connection_string=mongo_connection_string\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41df2abb",
   "metadata": {},
   "source": [
    "### Routing Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d1a7711",
   "metadata": {},
   "outputs": [],
   "source": [
    "routes = [\n",
    "    {\n",
    "        \"condition\": \"{{ replies[0] == 'products'}}\", \n",
    "        \"output\": [\"{{ query_embedding }}\",\"{{ query }}\"],             \n",
    "        \"output_name\": [\"products_route_embedding\" , \"products_route_query\"],        \n",
    "        \"output_type\": [list[float], str]             \n",
    "    },\n",
    "    {\n",
    "        \"condition\": \"{{ replies[0] == 'common'}}\", \n",
    "        \"output\": [\"{{ query_embedding }}\",\"{{ query }}\"],\n",
    "        \"output_name\": [\"common_route_embedding\" , \"common_route_query\"],\n",
    "        \"output_type\": [list[float], str]\n",
    "    }\n",
    "]\n",
    "router = ConditionalRouter(routes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b71444",
   "metadata": {},
   "source": [
    "## Membuat Paraphraser Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89d791d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParaphraserPipeline:\n",
    "    def __init__(self,chat_message_store):\n",
    "        self.memory_retriever = ChatMessageRetriever(chat_message_store)\n",
    "        self.pipeline = Pipeline()\n",
    "        self.pipeline.add_component(\"prompt_builder\",ChatPromptBuilder(variables=[\"query\",\"memories\"],required_variables=[\"query\", \"memories\"],))\n",
    "        self.pipeline.add_component(\"generator\", OpenAIChatGenerator(model=\"gpt-4.1-2025-04-14\", api_key=Secret.from_token(os.environ[\"OPENAI_API_KEY\"])))\n",
    "        self.pipeline.add_component(\"memory_retriever\", self.memory_retriever)\n",
    "\n",
    "        self.pipeline.connect(\"prompt_builder.prompt\", \"generator.messages\")\n",
    "        self.pipeline.connect(\"memory_retriever\", \"prompt_builder.memories\")\n",
    "    \n",
    "    def run(self, query):\n",
    "        messages = [\n",
    "            ChatMessage.from_system(\n",
    "                \"You are a helpful assistant that paraphrases user queries based on previous conversations.\"\n",
    "            ),\n",
    "            ChatMessage.from_user(\n",
    "                \"\"\"\n",
    "                Please paraphrase the following query based on the conversation history provided below. If the conversation history is empty, please return the query as is.\n",
    "                history:\n",
    "                {% for memory in memories %}\n",
    "                    {{memory.text}}\n",
    "                {% endfor %}\n",
    "                query: {{query}}\n",
    "                answer:\n",
    "                \"\"\"\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        res = self.pipeline.run(\n",
    "            data = {\n",
    "                \"prompt_builder\":{\n",
    "                    \"query\": query,\n",
    "                    \"template\": messages\n",
    "                },\n",
    "            \n",
    "            },\n",
    "            include_outputs_from=[\"generator\"]\n",
    "        )\n",
    "        print(\"Pipeline Input\", query)\n",
    "        return res[\"generator\"][\"replies\"][0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bff867b",
   "metadata": {},
   "source": [
    "## Membuat History Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce2d47ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatHistoryPipeline:\n",
    "    def __init__(self, chat_message_store):\n",
    "        self.chat_message_store = chat_message_store\n",
    "        self.pipeline = Pipeline()\n",
    "        self.pipeline.add_component(\"memory_retriever\", ChatMessageRetriever(chat_message_store))\n",
    "        self.pipeline.add_component(\"prompt_builder\", PromptBuilder(variables=[\"memories\"], required_variables=[\"memories\"], template=\"\"\"\n",
    "        Previous Conversations history:\n",
    "        {% for memory in memories %}\n",
    "            {{memory.text}}\n",
    "        {% endfor %}\n",
    "        \"\"\")\n",
    "        )\n",
    "        self.pipeline.connect(\"memory_retriever\", \"prompt_builder.memories\")\n",
    "\n",
    "    def run(self):\n",
    "        res = self.pipeline.run(\n",
    "            data = {},\n",
    "            include_outputs_from=[\"prompt_builder\"]\n",
    "        )\n",
    "\n",
    "        return res[\"prompt_builder\"][\"prompt\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d506ce",
   "metadata": {},
   "source": [
    "## Membuat routing tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d586919a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RoutingPipeline: \n",
    "    def __init__(self, router):\n",
    "        self.router = router\n",
    "        self.pipeline = Pipeline()\n",
    "\n",
    "        router_prompt_template = [\n",
    "            ChatMessage.from_system( \"\"\"\n",
    "                You are a routing classifier.\n",
    "                Return EXACTLY ONE of the following strings:\n",
    "                products\n",
    "                common\n",
    "\n",
    "                STRICT RULES:\n",
    "                - DO NOT add quotes\n",
    "                - DO NOT add punctuation\n",
    "                - DO NOT add explanation\n",
    "                - DO NOT add extra words\n",
    "                - ONLY return exactly: products OR common\n",
    "\n",
    "                Examples:\n",
    "                Query: What is the price of this bag\n",
    "                Answer: products\n",
    "\n",
    "                Query: How do I return my order\n",
    "                Answer: common\n",
    "\n",
    "                Query: Does this bag come in red\n",
    "                Answer: products\n",
    "\n",
    "                Query: I want a refund for my last order\n",
    "                Answer: common\"\n",
    "                \"\"\"\n",
    "            ),\n",
    "            ChatMessage.from_user(\"{{ query }}\")\n",
    "       ]\n",
    "\n",
    "        self.pipeline.add_component(\"embedder\", SentenceTransformersTextEmbedder())\n",
    "        self.pipeline.add_component(\"decision\", OpenAIChatGenerator(model=\"gpt-4.1\", api_key=openai_api_key))        \n",
    "        self.pipeline.add_component(\"prompt_builder_router\", ChatPromptBuilder(template=router_prompt_template))\n",
    "        self.pipeline.add_component(\"router\", router)\n",
    "        \n",
    "        self.pipeline.connect(\"embedder.embedding\", \"router.query_embedding\")\n",
    "        self.pipeline.connect(\"prompt_builder_router.prompt\", \"decision\")\n",
    "        self.pipeline.connect(\"decision.replies\", \"router.replies\")\n",
    "\n",
    "    def run(self, query):\n",
    "        \n",
    "        res = self.pipeline.run(\n",
    "            data={\n",
    "                \"prompt_builder_router\": {\"query\" : query},\n",
    "                \"embedder\": {\"text\" : query},\n",
    "                \"router\": {\"query\": query}\n",
    "            }, \n",
    "            include_outputs_from=[\"router\", \"decision\"]\n",
    "        )\n",
    "        try:\n",
    "            return res[\"decision\"][\"replies\"][0]\n",
    "        except (KeyError, IndexError):\n",
    "            return \"routing_failed\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1724f1ec",
   "metadata": {},
   "source": [
    "## Membuat Route Common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c66e731",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CommonRoute:\n",
    "    def __init__(self, document_store_common):\n",
    "        self.document_store_product = document_store_common\n",
    "        template_common_message = [\n",
    "            ChatMessage.from_system(\n",
    "            \"\"\"\n",
    "            You are smart personal assistant system to help customer find common information\n",
    "            Answer the user's question using only the provided context.\n",
    "            Maintain the same language as the question.   \n",
    "            Context:\n",
    "            {{ context | map(attribute='content') | join(\" \") | replace(\"\\n\", \" \")}}   \n",
    "            Instructions:\n",
    "            1. Only use information from the context to answer.\n",
    "            2. If the context does not contain the required Context, respond with:\n",
    "            \"I'm sorry, I can't answer that right now.\"\n",
    "            3. Keep the answer concise and clear.          \n",
    "            \"\"\"\n",
    "        ),\n",
    "            ChatMessage.from_user(\n",
    "                \"{{ query }}\"\n",
    "            )\n",
    "        ]\n",
    "        self.pipeline = Pipeline()\n",
    "        self.pipeline.add_component(\"retriever_common\", MongoDBAtlasEmbeddingRetriever( document_store=document_store_common, top_k=6))\n",
    "        self.pipeline.add_component(\"prompt_builder_common\", ChatPromptBuilder(template=template_common_message))\n",
    "        self.pipeline.add_component(\"generator_common\", OpenAIChatGenerator(api_key=openai_api_key, model=\"gpt-4.1\"))\n",
    "\n",
    "        self.pipeline.connect(\"retriever_common.documents\", \"prompt_builder_common.documents\")\n",
    "        self.pipeline.connect(\"prompt_builder_common.prompt\", \"generator_common.prompt\")\n",
    "    def run(self, query_embedding, query):\n",
    "        res = self.pipeline.run(\n",
    "            data={\n",
    "                \"prompt_builder_common\":{\"query\" : query},\n",
    "                \"retriever_common\":{\"query_embedding\" : query_embedding}\n",
    "            }, include_outputs_from=[\"generator_common\"]\n",
    "        )\n",
    "        return res[\"generator\"][\"replies\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f2833c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "day45-haystack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
